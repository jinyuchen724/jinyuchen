# Spark on Kubernetes 项目技术文档

## 目录

1. [项目概述](#项目概述)
2. [架构设计](#架构设计)
3. [资源管理](#资源管理)
4. [监控运维](#监控运维)
5. [部署实施](#部署实施)
6. [故障排查](#故障排查)
7. [最佳实践](#最佳实践)
8. [未来规划](#未来规划)

---

## 项目概述

### 背景与目标

**项目背景**
我们之前通过 K8s+Yarn 实现了全天常态化混部，混部能力是通过两套不同调度器实现，彼此间无法高效地交互细粒度的资源信息。为了解决这个问题，我们打算以 K8s 作为基础，通过二次开发的方式实现统一调度架构，将 Spark 也调度到 K8s 进行管理。

**核心目标**
- 实现 K8s 统一调度架构，将 Spark 任务调度到 K8s 进行管理
- 从 K8s+Yarn 混部方案迁移到 K8s 统一调度
- 提升资源利用率，实现常态化混部能力

**业务价值**
- 调度到在线混部集群的任务整体耗时降低 60%
- 离线混部机房不采购机器情况下，承载了 10% 的在线业务流量
- 混部规模 1w+ 核心，涵盖 500+ 在线业务、flink 实时任务，4000+ 离线任务

![常态化混部](../images/sparkOnK8s1.png)

---

## 架构设计

### Spark on K8s 技术选型

我们离线任务大部分都已经迁移到了 Spark，Spark 任务运行在 K8s 有 2 种方式：spark submit on k8s 和 spark operator on k8s。

#### Spark Submit on K8s 架构

![spark submit on k8s架构图](../images/sparkOnK8s2.png)

**方案特点**
- 以 spark-submit 方式提交到 K8s 集群是 Spark 在 2.3 版本后提供的原生功能
- 客户端通过 spark-submit 设置 K8s 的相关参数，内部再调用 K8s API 在 K8s 集群中创建 Driver Pod
- Driver 再调用 K8s API 创建需要的 Executor Pod，共同组成 Spark Application
- 作业结束后 Executor Pod 会被 Driver Pod 销毁，而 Driver Pod 则继续存在直到被清理

**优势**
- 使用 spark-submit 方式的最大好处是由 spark-submit 来与 K8s 进行交互
- 提交作业的方式几乎保持一致，便于现有系统集成

**劣势**
- 使用非声明式的提交接口，如果需要修改 K8s 配置就需要重新开发新接口
- 二次开发复杂繁琐，虽然 Spark 提供了大量的 K8s 配置参数，但也远比不了 K8s YAML 的声明式提交方式更加灵活
- Spark Application 和 K8s Workload 的生命周期还不能较好地对应起来
- 生命周期不能灵活控制，任务监控也比较难接入 Prometheus 集群监控

#### Spark Operator on K8s 架构

![spark operator on k8s架构图](../images/sparkOnK8s3.png)

**方案特点**
- spark-submit 是离线任务提交的思维，而 Spark Operator 方式更倾向于 K8s 作业的思维
- 作为 K8s 的自定义控制器，在集成了原生的 Spark on K8s 的基础上利用 K8s 原生能力提供了更全面管控功能
- 使用声明式的 YAML 提交 Spark 作业，并提供额外组件来管理 Spark 作业的生命周期

**核心组件**
- **SparkApplication 控制器**：负责 SparkApplication Object 的创建、更新和删除，同时处理各种事件和作业状态
- **Submission Runner**：负责调用 spark-submit 提交 Spark 作业，Driver 和 Executor 的运行流程是一致的
- **Spark Pod Monitor**：负责监控和同步 Spark 作业相关 Pod 的状态

**优势**
- 为在 K8s 中的 Spark 作业提供了更好的控制、管理和监控的功能
- 可以更加紧密地与 K8s 结合并能灵活使用 K8s 各种特性来满足复杂场景，例如混部场景

**劣势**
- 不再像 spark-submit 那样方便地提交任务
- 如何使用 Spark Operator 优雅提交任务将是在离线混部中一项重要的工作

#### 技术选型决策

**最终选择：Spark Submit on K8s**

选择理由：
1. 整个离线调度系统通过接入 Kyuubi 统一了任务提交的方式，submit 方式更符合我们现在的管理模式
2. 通过配置管理系统可以动态地将 K8s 的参数弄到 pod 模板，将 spark 的参数统一到配置中心管理
3. 这种模式更符合我们整个系统生态

### 混合部署架构设计

#### 混部整体架构

![混部整体架构](./images/hybrid2.png)

#### 混部单节点视图

![混部单节点视图](./images/hybrid3.png)

上面的整体架构图介绍了我们目前在离线混部的整体架构，涉及到的组件比较多，混部的服务相对也比较复杂。这里从单个节点的软硬件角度来详细说明一下混部的资源分配逻辑。

#### 硬件资源分配

**CPU**
- 详细资源调度与资源隔离见后续章节

**内存**
- 同 CPU 处理逻辑

**磁盘**
- 同时使用了 HDD、SSD、NVMe
- **HDD**：主要用于 HDFS 存储数据（数据量特别大，只能 HDD，其他盘成本 cover 不住）
- **SSD**：主要用于操作系统、在线业务，在线业务与操作系统的盘也是隔离的（在线业务独立使用，在线业务延迟敏感，如果和离线任务共用做 IO 隔离也很难保障不受影响，所以直接从硬件上分开了）
- **NVMe**：主要用于离线任务写入的临时数据（IO 大，数据量大，读写速度越快越好，这样也能加速离线任务的产出），在线业务的盘也逐渐替换成 NVMe 了

**网络**
- 机器有 2 块万兆的物理网卡，然后 2 块做了 bond0
- mac0 为什么要 bridge 到 bond0？因为 K8s 中 macvlan 的网络模式下物理机网卡无法与自己虚拟出来的 macvlan 子网卡通讯，简单说就是如果用 bond0，物理机的 IP 就无法访问节点上 pod 的 IP，所以通过 bridge 一个 mac0 来让所有网络互通
- mac1、macxx 就是 K8s 利用 macvlan 虚拟出来的子网卡，这个网卡会挂载到 pod 里面
- pod 挂载的子网卡分配的 IP 也是与物理机网段隔离的，一个是为了做网络限制（如数据库白名单、公网访问，离线任务是不允许的），第二个就是为了做流量的限制

#### 软件组件架构

**核心组件**
- **kubelet**：用来启动在线业务容器的
- **nodemanager**：用来启动离线任务容器的
- **datanode**：存储离线业务数据
- **混部 agent**：用来调节节点资源隔离、资源监控、资源分配的 work 节点
- **混部 server**：下发资源策略、监控、稳定性诊断等是混部系统的大脑

---

## 资源管理

### 动态资源调度算法

资源调度核心解决的问题是当前时段内应该给不同类型的服务分配多少资源，分配的资源既能保证机器的资源利用率，又要能保证业务不会出问题。

我们经历了几个阶段如下：

![资源调度](./images/hybrid11.png)

#### 1. 静态计算资源

就是固定配比，手动设置后就不再自动变化，直到下一次重新设置。

刚开始就是按照这种来进行资源分配的，我们算好在线离线的资源量然后用系统给节点设置好。

#### 2. 分时计算资源

即在某些时间段关闭混部或者减少上报混部资源量。

顾名思义就是根据时间，不同时间段分配不同的资源，这个阶段我们经历的时间比较久，详细说一下案例：

![](./images/hybrid4.png)

1. 第一段时间是静态计算，计算完成后，可以看到除了 VSS（数据同步任务）使用的时间段内，其他时间段资源都是比较空闲的
2. 第二段时间内采用分时策略，在 3 点提高离线 cgroup 资源
3. 第三段时间优化分时策略，根据 CPU 资源使用率去提高离线 cgroup 资源

可以看到，采用分时策略让凌晨整体资源利用率提高了，但是未来核心在线业务变多白天利用率还需要提高，而且如果在线业务核心业务继续迁移后，也不会使用太多 CPU，所以我们还需要进一步进行优化。

#### 3. 动态计算资源

针对各类物理资源，例如 CPU、memory 等，我们会分别设置机器的安全水位值 n%。agent 会实时探测在线进程的资源使用量 online_cgroup，然后根据安全水位和在线负载动态计算出可混部资源量。

![](./images/hybrid5.png)

动态计算资源这里的核心就是如何计算在线业务的资源使用量，这里我们是通过采集 K8s 下面的 kubepod.slice 这个目录中的 cgroup 来实现。具体如何实现下面混部监控详细介绍。

### 资源分配策略

#### 在线业务资源使用量较低时（online cgroup 小于 20%）

**CPU 资源分配**

| 应用分布 | CPU 资源占比 | 备注 |
|:---------|:-------------|:-----|
| 节点系统预留资源 | 10% | |
| 节点 K8s 资源配比 | 100%-10%-yarn资源% | |
| 节点 Yarn 资源配比 | 70%-在线cgroup% | |

**内存资源分配**

| 应用分布 | 内存资源占比 | 备注 |
|:---------|:-------------|:-----|
| 节点系统预留资源 | 10% | |
| 节点 K8s 资源配比 | 45% | |
| 节点 Yarn 资源配比 | 45%-50G(hdfs/nm使用) | |

#### 在线业务资源使用量较高时（online cgroup 大于 20%）

**CPU 资源分配**

| 应用分布 | CPU 资源占比 | 备注 |
|:---------|:-------------|:-----|
| 节点系统预留资源 | 10% | |
| 节点 K8s 资源配比 | 100%-10%-yarn资源% | |
| 节点 Yarn 资源配比 | 50%-在线cgroup% | |

**内存资源分配**

| 应用分布 | 内存资源占比 | 备注 |
|:---------|:-------------|:-----|
| 节点系统预留资源 | 10% | |
| 节点 K8s 资源配比 | 45% | |
| 节点 Yarn 资源配比 | 45%-在线cgroup%-50G(hdfs/nm使用) | |

### 资源限制与隔离

#### CPU、内存的限制与隔离

![cgroup](./images/hybrid8.png)

**实现方式**
1. 我们在计算完资源分配的比例后，会将这个信息告诉 resourcemanager，注册到 rm 的 nm 就会变成这个计算之后的资源，但是节点的资源限制是不会更改的，我们就通过修改 yarn cgroup 下面的 cpu 和 mem 来进行控制
2. 我们会将在线业务的 nice 值进行调低、越低优先级越高，当 CPU 资源发生抢占时可以优先保证计算资源分配给在线业务
3. 我们会将离线业务的 oom_score 分数设大，这样内存资源不足时也可以保证在线业务不会被优先 kill

#### 磁盘的限制与隔离

直接通过物理隔离的方式来实现的。所以也就无需进行限制了。

#### 网络的限制与隔离

网络是如何隔离的，那如何保证离线任务不会把物理机器网卡打满呢，我们现在是双万兆网卡，理论上很难打满，但是我们也对物理机 IP 进行了 tc 的限制，限制他的流量不能超过万兆。

### 稳定性保障机制

除了上面提到的资源分配、资源的隔离限制，我们还在混部系统里面实现了一个兜底的退避机制，防止异常情况下业务受到影响。

#### 兜底退避架构

![兜底退避架构图](./images/hybrid9.png)

#### 兜底退避流程

![兜底退避流程](./images/hybrid10.png)

虽然我们在资源调度、资源限制上做了很多策略，但是有些我们意想不到的异常情况可能还是会出现，所以做这个兜底机制目的还是保障核心业务的稳定性。

**触发条件**
- 当发现某些指标异常时（如 CPU 平均利用率大于 90%）我们会停止调度任务

**处理流程**
1. 持续进行观测，如果一直不恢复会按照离线任务资源占用且任务优先级（debug>P3>P2>P1）来进行驱逐
2. 提供对应的电话报警通知
3. 如果离线业务驱逐完还是未恢复我们就会认为节点有问题了，会驱逐所有业务，让运维人员进行介入排查具体问题

---

## 监控运维

### 混部监控体系

因为现有的监控系统无法去采集在线、离线业务的资源使用量，我们就通过混部的 agent 分别去采集他们的资源使用量。

#### Cgroup 数据采集

```shell
# cat /sys/fs/cgroup/cpu/kubepods.slice/cpuacct.usage
13018477833545639

# cat /sys/fs/cgroup/cpu/yarn/cpuacct.usage
1322136383859890057
```

#### Prometheus 集成实现

通过采集这个下面的 cgroup 数据，然后通过 agent 暴露 prometheus 接口，类似下面的方法，就可以获取到：

```java
public void YarnCpuCgroupGauge(MeterRegistry registry) {
    YarnCgroupCpu yarnCgroupCpu = new YarnCgroupCpu();
    Gauge.builder("yarn_cpu_cgroup_use_total", yarnCgroupCpu, yarnCgroupCpu::getCount)
            .tags("node", "yarn-cgroup")
            .description("yarn cpu累计使用时间")
            .register(registry);
}

public void K8sCpuCgroupGauge(MeterRegistry registry) {
    K8sCgroupCpu k8sCgroupCpu = new K8sCgroupCpu();
    Gauge.builder("k8s_cpu_cgroup_use_total", k8sCgroupCpu, k8sCgroupCpu::getCount)
            .tags("node", "k8s-cgroup")
            .description("k8s cpu累计使用时间")
            .register(registry);
}
```

#### 自动服务发现配置

接着我们通过暴露混部 agent 的接口，让 prometheus 进行采集，这个就是混部 agent 在 K8s 集群里面的配置，打上这个注解之后，prometheus 就会进行自动采集了：

```yaml
annotations:
    prometheus.io/path: /actuator/prometheus
    prometheus.io/port: "9090"
    prometheus.io/scrape: "true"
```

#### 监控看板

然后就可以根据这个数据来作为资源调度、监控的看板、报警的基础支撑了：

![监控看板](./images/hybrid7.png)

### 告警策略配置

#### 资源使用率阈值

- CPU 平均利用率 > 90%：触发兜底退避机制
- 内存使用率 > 85%：发出预警
- 磁盘使用率 > 90%：发出告警

#### 异常检测规则

- 内存直接回收检测
- 任务异常退出监控
- 网络流量异常监控

### 故障排查手册

#### 常见问题诊断

**1. 内存直接回收问题**

![内存直接回收](./images/hybrid6.png)

**问题描述**
和实时任务混部，而实时任务跑的 pod 比较多，节点整体内存使用就超了导致触发了系统的内存直接回收。

**解决方案**
计算了下当时节点内存分配的情况：
- flink 任务内存 130G
- yarn nm 分配的内存 (70%-17%)*376=200G
- hdfs+nodemanager=40G
- 总共 370G，基本会让节点内存占满了

优化内存的计算逻辑，主要是将 hdfs+nodemanager 这部分算进去，还有整体会限制内存不让他超过 90% 的使用率。

**2. 网络隔离问题**

**问题描述**
K8s 中 macvlan 的网络模式下物理机网卡无法与自己虚拟出来的 macvlan 子网卡通讯。

**解决方案**
通过 bridge 一个 mac0 来让所有网络互通。

---

## 部署实施

### 环境配置指南

#### K8s 集群配置

**节点配置要求**
- CPU：支持混部的多核心配置
- 内存：充足的内存资源支持在线和离线混部
- 存储：HDD、SSD、NVMe 多层存储配置
- 网络：双万兆网卡 bond 配置

**网络配置**
```yaml
# macvlan 网络配置示例
apiVersion: v1
kind: ConfigMap
metadata:
  name: macvlan-config
data:
  network: |
    {
      "cniVersion": "0.3.1",
      "type": "macvlan",
      "master": "bond0",
      "mode": "bridge",
      "ipam": {
        "type": "host-local",
        "subnet": "10.0.0.0/16",
        "gateway": "10.0.0.1"
      }
    }
```

#### Spark 参数优化

**基础配置**
```bash
spark.kubernetes.container.image=your-spark-image:latest
spark.kubernetes.driver.request.cores=1
spark.kubernetes.executor.request.cores=2
spark.kubernetes.driver.limit.cores=2
spark.kubernetes.executor.limit.cores=4
```

**资源配置**
```bash
spark.executor.memory=4g
spark.driver.memory=2g
spark.sql.adaptive.enabled=true
spark.sql.adaptive.coalescePartitions.enabled=true
```

### 迁移方案

#### 从 Yarn 环境到 K8s 的迁移步骤

**阶段一：环境准备**
1. 搭建 K8s 集群环境
2. 配置网络和存储
3. 部署 Spark on K8s 环境

**阶段二：试点迁移**
1. 选择非核心业务进行试点
2. 验证性能和稳定性
3. 调优配置参数

**阶段三：批量迁移**
1. 制定迁移计划
2. 业务逐步切换
3. 监控迁移过程

**阶段四：优化调优**
1. 根据监控数据进行优化
2. 资源配置调优
3. 性能参数调优

### 性能调优指南

#### 混部场景的性能优化建议

**1. 资源隔离优化**
- 合理配置 CPU nice 值
- 设置合适的 oom_score 值
- 使用 cgroup 进行资源限制

**2. 网络优化**
- 使用高速网络接口
- 配置网络流量限制
- 优化网络隔离策略

**3. 存储优化**
- 分层存储策略
- IO 优先级设置
- 磁盘性能监控

**4. 调度优化**
- 动态资源分配
- 智能任务调度
- 负载均衡策略

---

## 故障排查

### 常见故障及解决方案

#### 1. 资源争抢问题

**现象**
- 在线业务响应延迟增加
- 离线任务执行缓慢

**排查步骤**
1. 检查资源使用率监控
2. 查看 cgroup 资源分配情况
3. 分析任务调度情况

**解决方案**
- 调整资源分配策略
- 优化调度算法
- 增加资源隔离措施

#### 2. 网络连通性问题

**现象**
- Pod 无法访问外部服务
- 节点间通信异常

**排查步骤**
1. 检查网络配置
2. 验证 macvlan 设置
3. 测试网络连通性

**解决方案**
- 修复网络配置
- 重新配置 bridge
- 检查防火墙设置

#### 3. 存储空间不足

**现象**
- 任务执行失败
- 磁盘空间告警

**排查步骤**
1. 检查各层存储使用情况
2. 分析数据分布
3. 查看临时文件清理情况

**解决方案**
- 清理无用数据
- 调整存储分配策略
- 增加存储容量

### 监控告警处理

#### 告警处理流程

1. **接收告警** → 2. **初步诊断** → 3. **定位问题** → 4. **执行处理** → 5. **验证恢复** → 6. **总结归档**

#### 紧急故障处理

**P0 级别故障**
- 立即启动兜底退避机制
- 驱逐离线任务保障在线业务
- 通知相关人员进行紧急处理

**P1 级别故障**
- 30 分钟内响应
- 分析问题原因
- 制定解决方案

---

## 最佳实践

### 资源配置最佳实践

#### 1. CPU 配置建议

**在线业务**
- 设置较低的 nice 值（高优先级）
- 预留充足的 CPU 资源
- 避免 CPU 超分配

**离线业务**
- 使用动态 CPU 分配
- 根据负载调整资源
- 设置合理的 CPU 限制

#### 2. 内存配置建议

**避免内存超分配**
- 考虑系统预留内存
- 预留 HDFS 和 NodeManager 内存
- 设置内存使用上限

**内存隔离策略**
- 使用 cgroup 进行内存隔离
- 设置合适的 oom_score
- 监控内存使用情况

#### 3. 网络配置建议

**网络隔离**
- 使用不同网段隔离在线和离线业务
- 配置网络访问控制
- 监控网络流量

**网络性能优化**
- 使用高速网络接口
- 配置网络 bond
- 优化网络参数

### 监控配置最佳实践

#### 1. 关键指标监控

**资源使用率**
- CPU 使用率
- 内存使用率
- 磁盘使用率
- 网络使用率

**业务指标**
- 任务执行时间
- 任务成功率
- 响应延迟

#### 2. 告警配置

**分级告警**
- P0：紧急故障
- P1：重要问题
- P2：一般问题
- P3：提醒信息

**告警通知**
- 邮件通知
- 短信通知
- 钉钉群通知
- 电话告警（紧急情况）

### 运维管理最佳实践

#### 1. 变更管理

**变更流程**
1. 变更申请
2. 风险评估
3. 测试验证
4. 正式变更
5. 变更验证

**回滚策略**
- 准备回滚方案
- 设置回滚节点
- 快速回滚能力

#### 2. 容量规划

**资源预测**
- 基于历史数据预测
- 考虑业务增长
- 预留缓冲资源

**扩容策略**
- 水平扩容
- 垂直扩容
- 混合扩容

---

## 未来规划

### 短期目标（6个月内）

#### 1. 规模扩展
- 离线机房承载 20% 流量，替代之前的双机房
- 混部整体核心达到 3w+
- 完善 Spark on K8s 统一调度

#### 2. 功能完善
- 完善监控体系
- 优化调度算法
- 增强故障自愈能力

#### 3. 性能优化
- 进一步降低任务耗时
- 提升资源利用率
- 优化网络和存储性能

### 中期目标（1年内）

#### 1. 平台化建设
- 建设统一的混部管理平台
- 提供自服务能力
- 完善运维自动化

#### 2. 智能化升级
- 引入机器学习进行资源预测
- 智能故障诊断
- 自动化性能调优

#### 3. 生态完善
- 支持更多类型的工作负载
- 完善多云部署能力
- 增强安全性和合规性

### 长期目标（2年内）

#### 1. 技术演进
- 探索 Serverless 架构
- 支持边缘计算场景
- 引入云原生技术栈

#### 2. 标准化输出
- 形成行业标准和最佳实践
- 开源相关技术组件
- 建立技术社区

#### 3. 业务价值
- 实现更大规模的资源整合
- 支持更复杂的业务场景
- 创造更大的商业价值

---

## 附录

### 相关链接

- [Spark on K8s 官方文档](https://spark.apache.org/docs/latest/running-on-kubernetes.html)
- [Kubernetes 官方文档](https://kubernetes.io/docs/)
- [Prometheus 监控文档](https://prometheus.io/docs/)

### 团队联系方式

- **项目负责人**：[姓名] - [邮箱]
- **技术负责人**：[姓名] - [邮箱]
- **运维负责人**：[姓名] - [邮箱]

### 变更记录

| 版本 | 日期 | 变更内容 | 变更人 |
|------|------|----------|--------|
| 1.0 | 2024-XX-XX | 初始版本 | [姓名] |
| 1.1 | 2024-XX-XX | 添加监控章节 | [姓名] |
| 1.2 | 2024-XX-XX | 完善故障排查 | [姓名] |

---

*本文档将持续更新，请关注最新版本。*